{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cross correlation of images\n\nIn this demo the cross-correlation is calculated between two images\nacquired via the integrated webcam of your PC.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from itom import dataIO\nfrom itom import dataObject\nfrom itom import ui\nimport numpy as np\nfrom numpy import fft\n\n\n# some methods\ndef acquireImage1():\n    g = cam.getAutoGrabbing()\n    cam.setAutoGrabbing(False)\n    cam.acquire()\n    cam.copyVal(image1)\n    gui.plot1[\"source\"] = image1\n    cam.setAutoGrabbing(g)\n\n\ndef acquireImage2():\n    g = cam.getAutoGrabbing()\n    cam.setAutoGrabbing(False)\n    cam.acquire()\n    cam.copyVal(image2)\n    gui.plot2[\"source\"] = image2\n    cam.setAutoGrabbing(g)\n\n\ndef evaluate():\n    \"\"\"determines the offset between image1 and image2\n    using cross-correlation and returns a tuple containing\n    the shift in x and y-direction\"\"\"\n\n    npImg1 = np.array(image1)\n    npImg2 = np.array(image2)\n\n    npImg1FFT = fft.fft2(npImg1)\n    npImg2FFT = fft.fft2(npImg2)\n    ccr = fft.ifft2(npImg1FFT * npImg2FFT.conj())\n    ccr_abs = np.abs(ccr)  # np.ascontiguousarray(np.abs(ccr))\n\n    [m, n] = ccr_abs.shape\n    max_pos = np.argmax(ccr_abs)\n    offset_x = max_pos % n\n    offset_y = (max_pos - offset_x) / n\n\n    if offset_x > n / 2:\n        offset_x = offset_x - n\n    if offset_y > m / 2:\n        offset_y = offset_y - m\n\n    gui.lbl_dx[\"text\"] = \"dx: \" + str(offset_x)\n    gui.lbl_dy[\"text\"] = \"dy: \" + str(offset_y)\n\n\ndef saveImages():\n    filename = ui.getSaveFileName(\"Filename\", filters=\"IDC (*.idc)\", parent=gui)\n    if filename:\n        saveIDC(filename, {\"image1\": image1, \"image2\": image2})\n\n\ndef loadImages():\n    global image1\n    global image2\n    filename = ui.getOpenFileName(\"Filename\", filters=\"IDC (*idc)\", parent=gui)\n    if filename:\n        d = loadIDC(filename)\n        image1 = d[\"image1\"]\n        image2 = d[\"image2\"]\n        gui.plot1[\"source\"] = image1\n        gui.plot2[\"source\"] = image2\n\n\n# open camera (make it before you start this script)\ntry:\n    cam = dataIO(\"OpenCVGrabber\", colorMode=\"gray\")\nexcept:\n    print(\"Can not open camera with OpenCVGrabber. Probabel root cause: WebCam is not available.\")\n    print(\"Used Itom Dummy Grabber instead.\")\n    cam = dataIO(\"DummyGrabber\")\n\n# start camera\ncam.startDevice()\n\n# create data objects\nimage1 = dataObject()\nimage2 = dataObject()\n\n# create gui\ngui = ui(\"dialog.ui\", ui.TYPEWINDOW)\ngui.btnAcquire1.connect(\"clicked()\", acquireImage1)\ngui.btnAcquire2.connect(\"clicked()\", acquireImage2)\ngui.btnLoad.connect(\"clicked()\", loadImages)\ngui.btnSave.connect(\"clicked()\", saveImages)\ngui.btnEval.connect(\"clicked()\", evaluate)\n\n# show live image in upper plot\nif cam.name() != \"FileGrabber\":\n    cam.setAutoGrabbing(True)\nelse:\n    cam.setAutoGrabbing(False)\n\ngui.plotLive[\"camera\"] = cam\ngui.plotLive[\"keepAspectRatio\"] = True\ngui.plotLive[\"yAxisFlipped\"] = True\n\ngui.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}