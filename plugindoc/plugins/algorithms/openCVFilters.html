
<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>5.8. OpenCV Filters &#8212; itom Plugins</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/html.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/sphinx_highlight.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'plugins/algorithms/openCVFilters';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="5.9. PclTools" href="pclTools.html" />
    <link rel="prev" title="5.7. Fringe Proj" href="fringeProj.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
<div class="bd-header__inner bd-page-width">
  <label class="sidebar-toggle primary-toggle" for="__primary">
    <span class="fa-solid fa-bars"></span>
  </label>
  
  <div class="navbar-header-items__start">
    
      <div class="navbar-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    <p class="title logo__title">itom Plugins</p>
  
</a></div>
    
  </div>
  
  
  <div class="col-lg-9 navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../grabbers.html">
                        Camera/ Grabber
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../actuators.html">
                        Motors/ Actuators
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../GDIO.html">
                        General Data IO
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../adconv.html">
                        AD-Converters
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../algorithms.html">
                        Algorithms/ Filters
                      </a>
                    </li>
                
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
        </div>
      
      
        <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/itom-project/plugins" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://www.ito.uni-stuttgart.de/" title="ITO" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><img src="../../_static/ITO_Logo_neu_II.png" class="icon-link-image" alt="ITO"/></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">
<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
    </div>
  

  
    <label class="sidebar-toggle secondary-toggle" for="__secondary">
      <span class="fa-solid fa-outdent"></span>
    </label>
  
</div>

    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          <div class="navbar-item"><nav class="navbar-nav">
  <p class="sidebar-header-items__title"
     role="heading"
     aria-level="1"
     aria-label="Site Navigation">
    Site Navigation
  </p>
  <ul class="bd-navbar-elements navbar-nav">
    
                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../grabbers.html">
                        Camera/ Grabber
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../actuators.html">
                        Motors/ Actuators
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../GDIO.html">
                        General Data IO
                      </a>
                    </li>
                

                    <li class="nav-item">
                      <a class="nav-link nav-internal" href="../adconv.html">
                        AD-Converters
                      </a>
                    </li>
                

                    <li class="nav-item current active">
                      <a class="nav-link nav-internal" href="../algorithms.html">
                        Algorithms/ Filters
                      </a>
                    </li>
                
  </ul>
</nav></div>
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">
<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links navbar-nav"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/itom-project/plugins" title="GitHub" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><span><i class="fa-brands fa-github"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://www.ito.uni-stuttgart.de/" title="ITO" class="nav-link" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><img src="../../_static/ITO_Logo_neu_II.png" class="icon-link-image" alt="ITO"/></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item"><nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="BasicGPLFilters.html">5.1. Basic GPL Filters</a></li>
<li class="toctree-l1"><a class="reference internal" href="basicFilters.html">5.2. Basic Filters</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataObjectArithmetic.html">5.3. DataObject Arithmetic</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataObjectIO.html">5.4. DataObjectIO</a></li>
<li class="toctree-l1"><a class="reference internal" href="fftwFilters.html">5.5. FFTW-Filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="fittingFilters.html">5.6. Fitting Filters</a></li>
<li class="toctree-l1"><a class="reference internal" href="fringeProj.html">5.7. Fringe Proj</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">5.8. OpenCV Filters</a></li>
<li class="toctree-l1"><a class="reference internal" href="pclTools.html">5.9. PclTools</a></li>
<li class="toctree-l1"><a class="reference internal" href="rawImport.html">5.10. RawImport filters</a></li>
<li class="toctree-l1"><a class="reference internal" href="roughness.html">5.11. Roughness</a></li>
<li class="toctree-l1"><a class="reference internal" href="x3pio.html">5.12. X3P Input Output</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumbs">
  <ul class="bd-breadcrumbs" role="navigation" aria-label="Breadcrumb">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../algorithms.html" class="nav-link"><span class="section-number">5. </span>Algorithms/ Filters</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="section-number">5.8. </span>OpenCV Filters</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section id="opencv-filters">
<h1><span class="section-number">5.8. </span>OpenCV Filters<a class="headerlink" href="#opencv-filters" title="Permalink to this heading">#</a></h1>
<table class="table">
<tbody>
<tr class="row-odd"><td><p><strong>Summary</strong>:</p></td>
<td><p><span>Wrapped algorithms from OpenCV</span></p></td>
</tr>
<tr class="row-even"><td><p><strong>Type</strong>:</p></td>
<td><p><span>Algorithm</span></p></td>
</tr>
<tr class="row-odd"><td><p><strong>License</strong>:</p></td>
<td><p><span>LGPL</span></p></td>
</tr>
<tr class="row-even"><td><p><strong>Platforms</strong>:</p></td>
<td><p>Windows, Linux</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Author</strong>:</p></td>
<td><p><span>W. Lyda, M. Gronle, J. Krauter, ITO, University Stuttgart</span></p></td>
</tr>
</tbody>
</table>
<section id="overview">
<h2><span class="section-number">5.8.1. </span>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">#</a></h2>
<p>This plugin provides wrappers for various OpenCV algorithms. These are for instance:</p>
<ul class="simple">
<li><p>morphological filters (dilation, erosion)</p></li>
<li><p>image filtering (blur, median blur…)</p></li>
<li><p>1d and 2d fft and ifft</p></li>
<li><p>histogram determination</p></li>
<li><p>feature detections (circles, chessboard corners…)</p></li>
</ul>
<p>This plugin not only requires access to the core library of OpenCV but also to further libraries like imgproc and calib3d.</p>
<p>This plugin has been created at a time when OpenCV did not yet provide bindings for Python 3.
From OpenCV 3 on, these bindings exist. Therefore, it is possible to access almost all OpenCV
methods via the cv2 python package. The wrapped methods within this plugin can still be used;
In addition to the cv2 methods, they can sometimes operate on multi-plane dataObjects, preserve
the tags and meta information and save protocol data.</p>
<p>These filters are defined in the plugin:</p>
<ol class="arabic simple">
<li><p><a class="reference internal" href="#itom.algorithms.cvBilateralFilter" title="itom.algorithms.cvBilateralFilter"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvBilateralFilter()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvBlur" title="itom.algorithms.cvBlur"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvBlur()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvCalibrateCamera" title="itom.algorithms.cvCalibrateCamera"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvCalibrateCamera()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvCannyEdge" title="itom.algorithms.cvCannyEdge"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvCannyEdge()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvComputeCorrespondEpilines" title="itom.algorithms.cvComputeCorrespondEpilines"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvComputeCorrespondEpilines()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvCornerSubPix" title="itom.algorithms.cvCornerSubPix"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvCornerSubPix()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvCvtColor" title="itom.algorithms.cvCvtColor"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvCvtColor()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvDilate" title="itom.algorithms.cvDilate"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvDilate()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvDrawChessboardCorners" title="itom.algorithms.cvDrawChessboardCorners"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvDrawChessboardCorners()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvDrawKeypoints" title="itom.algorithms.cvDrawKeypoints"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvDrawKeypoints()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvDrawMatcher" title="itom.algorithms.cvDrawMatcher"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvDrawMatcher()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvErode" title="itom.algorithms.cvErode"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvErode()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvEstimateAffine3DParams" title="itom.algorithms.cvEstimateAffine3DParams"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvEstimateAffine3DParams()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvFFT1D" title="itom.algorithms.cvFFT1D"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvFFT1D()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvFFT2D" title="itom.algorithms.cvFFT2D"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvFFT2D()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvFindChessboardCorners" title="itom.algorithms.cvFindChessboardCorners"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvFindChessboardCorners()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvFindCircles" title="itom.algorithms.cvFindCircles"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvFindCircles()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvFindFundamentalMat" title="itom.algorithms.cvFindFundamentalMat"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvFindFundamentalMat()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvFindHomography" title="itom.algorithms.cvFindHomography"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvFindHomography()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvFlannBasedMatcher" title="itom.algorithms.cvFlannBasedMatcher"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvFlannBasedMatcher()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvFlipLeftRight" title="itom.algorithms.cvFlipLeftRight"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvFlipLeftRight()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvFlipUpDown" title="itom.algorithms.cvFlipUpDown"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvFlipUpDown()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvGetRotationMatrix2D" title="itom.algorithms.cvGetRotationMatrix2D"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvGetRotationMatrix2D()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvIFFT1D" title="itom.algorithms.cvIFFT1D"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvIFFT1D()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvIFFT2D" title="itom.algorithms.cvIFFT2D"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvIFFT2D()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvInitUndistortRectifyMap" title="itom.algorithms.cvInitUndistortRectifyMap"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvInitUndistortRectifyMap()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvMedianBlur" title="itom.algorithms.cvMedianBlur"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvMedianBlur()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvMergeChannels" title="itom.algorithms.cvMergeChannels"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvMergeChannels()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvMorphologyEx" title="itom.algorithms.cvMorphologyEx"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvMorphologyEx()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvProjectPoints" title="itom.algorithms.cvProjectPoints"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvProjectPoints()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvRemap" title="itom.algorithms.cvRemap"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvRemap()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvRemoveSpikes" title="itom.algorithms.cvRemoveSpikes"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvRemoveSpikes()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvResize" title="itom.algorithms.cvResize"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvResize()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvRotate180" title="itom.algorithms.cvRotate180"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvRotate180()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvRotateM90" title="itom.algorithms.cvRotateM90"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvRotateM90()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvRotateP90" title="itom.algorithms.cvRotateP90"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvRotateP90()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvSplitChannels" title="itom.algorithms.cvSplitChannels"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvSplitChannels()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvThreshold" title="itom.algorithms.cvThreshold"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvThreshold()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvUndistort" title="itom.algorithms.cvUndistort"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvUndistort()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvUndistortPoints" title="itom.algorithms.cvUndistortPoints"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvUndistortPoints()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvWarpAffine" title="itom.algorithms.cvWarpAffine"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvWarpAffine()</span></code></a></p></li>
<li><p><a class="reference internal" href="#itom.algorithms.cvWarpPerspective" title="itom.algorithms.cvWarpPerspective"><code class="xref py py-meth docutils literal notranslate"><span class="pre">cvWarpPerspective()</span></code></a></p></li>
</ol>
</section>
<section id="filters">
<h2><span class="section-number">5.8.2. </span>Filters<a class="headerlink" href="#filters" title="Permalink to this heading">#</a></h2>
<p>Detailed overview about all defined filters:</p>
<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvBilateralFilter">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvBilateralFilter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputObject</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputObject</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">diameter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigmaColor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigmaSpace</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">borderType</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvBilateralFilter" title="Permalink to this definition">#</a></dt>
<dd><p>Resizes an image</p>
<p>The function resize resizes the image ‘inputObject’ down to or up by the specific factors.</p>
<p>To shrink an image, it will generally look best with CV_INTER_AREA interpolation, whereas to enlarge an image,
it will generally look best with CV_INTER_CUBIC (slow) or CV_INTER_LINEAR (faster but still looks OK).
The axisScale properties of the x- and y-axes of the outputObject are divided by fx and fy respectively, while the offset values are multiplied with fx and fy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputObject</strong> (<em>itom.dataObject</em>) – input image (8-bit or floating-point, 1-Channel or 3-Channel)</p></li>
<li><p><strong>outputObject</strong> (<em>itom.dataObject</em>) – output image, will have the same type and size than inputObject.</p></li>
<li><p><strong>diameter</strong> (<em>int</em>) – <p>diameter of each pixel neighborhood that is used during filtering. If it is non-positive, it is computed from sigmaSpace..</p>
<div class="line-block">
<div class="line"><em>All values allowed, Default: 1</em></div>
</div>
</p></li>
<li><p><strong>sigmaColor</strong> (<em>float</em>) – <p>Filter sigma in the color space. A larger value of the parameter means that farther colors within the pixel neighborhood (see sigmaSpace) will be mixed together, resulting in larger areas of semi-equal color.</p>
<div class="line-block">
<div class="line"><em>Value range: [1e-06, inf], Default: 1</em></div>
</div>
</p></li>
<li><p><strong>sigmaSpace</strong> (<em>float</em>) – <p>Filter sigma in the coordinate space. A larger value of the parameter means that farther pixels will influence each other as long as their colors are close enough (see sigmaColor ). When diameter&gt;0, it specifies the neighborhood size regardless of sigmaSpace. Otherwise, diameter is proportional to sigmaSpace..</p>
<div class="line-block">
<div class="line"><em>Value range: [1e-06, inf], Default: 1</em></div>
</div>
</p></li>
<li><p><strong>borderType</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>border mode used to extrapolate pixels outside of the image. The following values are possible:</p>
<p>BORDER_CONSTANT (0) (iiiiii|abcdefgh|iiiiiii with some specified i)
BORDER_REPLICATE (1) (aaaaaa|abcdefgh|hhhhhhh)
BORDER_REFLECT  (2) (fedcba|abcdefgh|hgfedcb)
BORDER_WRAP (3) (cdefgh|abcdefgh|abcdefg)
BORDER_TRANSPARENT (4) (gfedcb|abcdefgh|gfedcba)
BORDER_ISOLATED (4) (do not look outside of ROI)</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 4], Default: 4</em></div>
</div>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvBlur">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvBlur</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sourceImage</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destinationImage</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">kernelSizeX</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernelSizeY</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anchor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">borderType</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvBlur" title="Permalink to this definition">#</a></dt>
<dd><p>Planewise median blur filter.</p>
<p>This filter applies the method cv::blur to every plane in the source data object. The function smoothes the images by a simple mean-filter. Theresult is contained in the destination object. It can handle data objects of type uint8, uint16, int16, ito::tInt32, float32 and float64 only.</p>
<p>The cv::blur interally calls the cv::boxfilter()-method.</p>
<p>The itom-wrapping does not work inplace currently. A new dataObject is allocated.</p>
<p>borderType: This string defines how the filter should hande pixels at the border of the matrix.Allowed is CONSTANT [default], REPLICATE, REFLECT, WRAP, REFLECT_101. In case of a constant border, only pixels inside of the element mask are considered (morphologyDefaultBorderValue)
Warning: NaN-handling for floats not verified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sourceImage</strong> (<em>itom.dataObject</em>) – All types except complex64 and complex128 are accepted</p></li>
<li><p><strong>destinationImage</strong> (<em>itom.dataObject</em>) – Empty object handle. Image will be of src-type</p></li>
<li><p><strong>kernelSizeX</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>Kernelsize for x-axis</p>
<div class="line-block">
<div class="line"><em>Value range: [1, 255], Default: 3</em></div>
</div>
</p></li>
<li><p><strong>kernelSizeY</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>Kernelsize for y-axis</p>
<div class="line-block">
<div class="line"><em>Value range: [1, 255], Default: 3</em></div>
</div>
</p></li>
<li><p><strong>anchor</strong> (<em>itom.dataObject</em><em>, </em><em>optional</em>) – Position of the kernel anchor, see openCV-Help</p></li>
<li><p><strong>borderType</strong> (<em>str</em><em>, </em><em>optional</em>) – border mode used to extrapolate pixels outside of the image</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvCalibrateCamera">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvCalibrateCamera</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">objectPoints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">imagePoints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">imageSize</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cameraMatrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distCoeffs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rvecs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tvecs</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">flags</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maxCounts</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilonAccuracy</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvCalibrateCamera" title="Permalink to this definition">#</a></dt>
<dd><p>Finds the camera intrinsic and extrinsic parameters from several views of a calibration pattern.</p>
<p>The function estimates the intrinsic camera parameters and extrinsic parameters for each of the views. The coordinates of 3D object points and their corresponding 2D projections in each view must be specified.
That may be achieved by using an object with a known geometry and easily detectable feature points. Such an object is called a calibration rig or calibration pattern, and OpenCV has built-in support for
a chessboard as a calibration rig (see cvFindChessboardCorners()). Currently, initialization of intrinsic parameters (when CV_CALIB_USE_INTRINSIC_GUESS is not set) is only implemented for planar
calibration patterns (where Z-coordinates of the object points must be all zeros). 3D calibration rigs can also be used as long as initial cameraMatrix is provided.</p>
<p>The algorithm performs the following steps:</p>
<ol class="arabic simple">
<li><p>Compute the initial intrinsic parameters (the option only available for planar calibration patterns) or read them from the input parameters. The distortion coefficients are all set to zeros initially unless some of CV_CALIB_FIX_K? are specified.</p></li>
<li><p>Estimate the initial camera pose as if the intrinsic parameters have been already known. This is done using solvePnP() .</p></li>
<li><p>Run the global Levenberg-Marquardt optimization algorithm to minimize the reprojection error, that is, the total sum of squared distances between the observed feature points imagePoints and the projected (using the current estimates for camera parameters and the poses) object points objectPoints. See projectPoints() for details.</p></li>
</ol>
<p>If the reprojectionError is NaN, one or both of the matrices objectPoints or imagePoints probabily contains any NaN-value after truncation. Remember that this algorithm truncates objectPoints and imagePoints
before using it in the way that for each view, the last rows are cut where either the value in the first column of objectPoints or imagePoints is non-finite.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>objectPoints</strong> (<em>itom.dataObject</em>) – [NrOfViews x NrOfPoints x 3] float32 matrix with the coordinates of all points in object space (coordinate system of calibration pattern).. Non-finite rows at the end of each matrix-plane will be truncated.</p></li>
<li><p><strong>imagePoints</strong> (<em>itom.dataObject</em>) – [NrOfViews x NrOfPoints x 2] float32 matrix with the pixel coordinates (u,v) of the corresponding plane in each view. Non-finite rows at the end of each matrix-plane will be truncated.</p></li>
<li><p><strong>imageSize</strong> (<em>Sequence</em><em>[</em><em>int</em><em>]</em>) – [height,width] of the camera image (in pixels)</p></li>
<li><p><strong>cameraMatrix</strong> (<em>itom.dataObject</em>) – Output 3x3 float64 camera patrix. If flags CV_CALIB_USE_INTRINSIC_GUESS and/or CV_CALIB_FIX_ASPECT_RATIO are specified, this matrix must be initialized with right values and is unchanged</p></li>
<li><p><strong>distCoeffs</strong> (<em>itom.dataObject</em>) – Output 1x4, 1x5 or 1x8 distortion values (float64). (k1, k2, p1, p2 [,k3 [,k4 ,k5 ,k6]])</p></li>
<li><p><strong>rvecs</strong> (<em>itom.dataObject</em>) – 3 x NrOfViews float64 output vector, where each column is the rotation vector estimated for each pattern view (Rodrigues coordinates)</p></li>
<li><p><strong>tvecs</strong> (<em>itom.dataObject</em>) – 3 x NrOfViews float64 output vector, where each column is the translation vector estimated for each pattern view</p></li>
<li><p><strong>flags</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>Different flags that may be a combination of the following values: CV_CALIB_USE_INTRINSIC_GUESS (1), CV_CALIB_FIX_PRINCIPAL_POINT (4), CV_CALIB_FIX_ASPECT_RATIO (2), CV_CALIB_ZERO_TANGENT_DIST (8), CV_CALIB_FIX_K1 (32), CV_CALIB_FIX_K2 (64), CV_CALIB_FIX_K3 (128), CV_CALIB_FIX_K4 (2048), CV_CALIB_FIX_K5 (4096), CV_CALIB_FIX_K6 (8192), CV_CALIB_RATIONAL_MODEL (16384)</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 30959], Default: 0</em></div>
</div>
</p></li>
<li><p><strong>maxCounts</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>if &gt; 0, maximum number of counts, 0: unlimited number of counts allowed [default: 30]</p>
<div class="line-block">
<div class="line"><em>Value range: [0, inf], Default: 30</em></div>
</div>
</p></li>
<li><p><strong>epsilonAccuracy</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>if &gt; 0.0, desired accuracy at which the iterative algorithm stops, 0.0: no epsilon criteria [default: DBL_EPSILON]</p>
<div class="line-block">
<div class="line"><em>Value range: [0, inf], Default: 2.22045e-16</em></div>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>reprojectionError - resulting re-projection error</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvCannyEdge">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvCannyEdge</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sourceImage</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destinationImage</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">lowThreshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">highThresholdRatio</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernelSize</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvCannyEdge" title="Permalink to this definition">#</a></dt>
<dd><p>Canny Edge detector using cv::DFT.</p>
<p>It’s just Canny’s edge filter</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sourceImage</strong> (<em>itom.dataObject</em>) – Input Object handle, must be a single plane</p></li>
<li><p><strong>destinationImage</strong> (<em>itom.dataObject</em>) – Output Object handle. Will be come complex-type</p></li>
<li><p><strong>lowThreshold</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>Low Threshold</p>
<div class="line-block">
<div class="line"><em>Value range: [-1e+10, 1e+10], Default: 2</em></div>
</div>
</p></li>
<li><p><strong>highThresholdRatio</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>Ratio between High Threshold and Low Threshold, Canny’s recommendation is three</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 1e+10], Default: 3</em></div>
</div>
</p></li>
<li><p><strong>kernelSize</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>Kernel size for Sobel filter, default is 3</p>
<div class="line-block">
<div class="line"><em>Value range: [3, 300], Default: 3</em></div>
</div>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvComputeCorrespondEpilines">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvComputeCorrespondEpilines</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">whichImage</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">F</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lines</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvComputeCorrespondEpilines" title="Permalink to this definition">#</a></dt>
<dd><p>For points in an image of a stereo pair, computes the corresponding epilines in the other image.</p>
<p>For every point in one of the two images of a stereo pair, the function finds the equation of the corresponding epipolar line in the other image.</p>
<p>From the fundamental matrix definition (see findFundamentalMat()), line l^{(2)}_i in the second image for the point p^{(1)}_i in the first image (when whichImage=1) is computed as:</p>
<div class="math">
<p><span class="math">l^{(2)}_i = F p^{(1)}_i</span></p>
</div><p>And vice versa, when whichImage=2, l^{(1)}_i is computed from p^{(2)}_i as:</p>
<div class="math">
<p><span class="math">l^{(1)}_i = F^T p^{(2)}_i</span></p>
</div><p>Line coefficients are defined up to a scale. They are normalized so that</p>
<div class="math">
<p><span class="math">a_i^2+b_i^2=1.</span></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>points</strong> (<em>itom.dataObject</em>) – coordinates of the image points in the one image, a matrix of type [Nx2], float32</p></li>
<li><p><strong>whichImage</strong> (<em>int</em>) – <p>Index of the image (1 or 2) that contains the points.</p>
<div class="line-block">
<div class="line"><em>Value range: [1, 2], Default: 1</em></div>
</div>
</p></li>
<li><p><strong>F</strong> (<em>itom.dataObject</em>) – Fundamental matrix that can be estimated using cvFindFundamentalMat() or cvStereoRectify()</p></li>
<li><p><strong>lines</strong> (<em>itom.dataObject</em>) – Output vector of the epipolar lines corresponding to the points in the other image. Each line ax + by + c=0 is encoded by 3 numbers (a, b, c)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvCornerSubPix">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvCornerSubPix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">corners</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">winSize</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">zeroZone</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maxCount</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epsilon</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvCornerSubPix" title="Permalink to this definition">#</a></dt>
<dd><p>Refines the corner locations e.g. from cvFindChessboardCorners.</p>
<p>This filter is a wrapper for the cv::method cv::cornerSubPix. Check the openCV-doku for more details</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>itom.dataObject</em>) – 8bit grayscale input image</p></li>
<li><p><strong>corners</strong> (<em>itom.dataObject</em>) – initial coordinates of the input corners and refined coordinates provided for output</p></li>
<li><p><strong>winSize</strong> (<em>Sequence</em><em>[</em><em>int</em><em>]</em>) – Half of the side length of the search window. Example: (5,5) leads to a (11x11) search window</p></li>
<li><p><strong>zeroZone</strong> (<em>Sequence</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>) – Half of the size of the dead region in the middle of the search zone over which the summation is not done. (-1,-1) indicates that there is no such a size</p></li>
<li><p><strong>maxCount</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>position refinement stops after this maximum number of iterations</p>
<div class="line-block">
<div class="line"><em>Value range: [1, 100000], Default: 200</em></div>
</div>
</p></li>
<li><p><strong>epsilon</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>position refinement stops when the corner position moves by less than this value</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 10], Default: 0.05</em></div>
</div>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvCvtColor">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvCvtColor</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sourceImage</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destinationImage</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">code</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dstChan</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvCvtColor" title="Permalink to this definition">#</a></dt>
<dd><p>Converts an image from one color space to another.
In case of linear transformations, the range does not matter. But in case of a non-linear transformation,
an input RGB image should be normalized to the proper value range to get the correct results, for example,
for RGB -&gt; L*u*v* transformation. For example, if you have a 32-bit floating-point image directly
converted from an 8-bit image without any scaling, then it will have the 0..255 value range instead of 0..1
assumed by the function. So, before calling cvtColor , you need first to scale the image down</p>
<p>The parameter code defines the conversion:</p>
<ul class="simple">
<li><p>RGB &lt;-&gt; GRAY ( CV_BGR2GRAY = 6, CV_RGB2GRAY = 7 , CV_GRAY2BGR = 8, CV_GRAY2RGB = 8)</p></li>
<li><p>RGB &lt;-&gt; CIE XYZ.Rec 709 with D65 white point ( CV_BGR2XYZ = 32, CV_RGB2XYZ = 33, CV_XYZ2BGR = 34, CV_XYZ2RGB = 35)</p></li>
<li><p>RGB &lt;-&gt; YCrCb JPEG (or YCC) ( CV_BGR2YCrCb = 36, CV_RGB2YCrCb = 37, CV_YCrCb2BGR = 38, CV_YCrCb2RGB = 39)</p></li>
<li><p>RGB &lt;-&gt; HSV ( CV_BGR2HSV = 40, CV_RGB2HSV = 41, CV_HSV2BGR = 54, CV_HSV2RGB = 55 )</p></li>
<li><p>RGB &lt;-&gt; HLS ( CV_BGR2HLS = 52, CV_RGB2HLS = 53, CV_HLS2BGR = 60, CV_HLS2RGB = 61)</p></li>
<li><p>RGB &lt;-&gt; CIE L*a*b* ( CV_BGR2Lab = 44, CV_RGB2Lab = 45, CV_Lab2BGR = 56, CV_Lab2RGB = 57)</p></li>
<li><p>RGB &lt;-&gt; CIE L*u*v* ( CV_BGR2Luv = 50, CV_RGB2Luv = 51, CV_Luv2BGR = 58, CV_Luv2RGB = 59)</p></li>
<li><dl class="simple">
<dt>Bayer &lt;-&gt; RGB ( CV_BayerBG2BGR = 46, CV_BayerGB2BGR = 47, CV_BayerRG2BGR = 48, CV_BayerGR2BGR = 49, …</dt><dd><p>CV_BayerBG2RGB = 48, CV_BayerGB2RGB = 49, CV_BayerRG2RGB = 46, CV_BayerGR2RGB = 47)</p>
</dd>
</dl>
</li>
</ul>
<p>For more details see OpenCV documentation.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sourceImage</strong> (<em>itom.dataObject</em>) – Input Object handle, must be a single plane</p></li>
<li><p><strong>destinationImage</strong> (<em>itom.dataObject</em>) – Output Object handle. Will be come complex-type</p></li>
<li><p><strong>code</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>Transformation code, see (OpenCV) documentation</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 65535], Default: 0</em></div>
</div>
</p></li>
<li><p><strong>dstChan</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>number of color channels of destination image, for 0 the number of channels is derived from the transformation (default)</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 5], Default: 0</em></div>
</div>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvDilate">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvDilate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sourceObj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destinationObj</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">element</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anchor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iterations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">borderType</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvDilate" title="Permalink to this definition">#</a></dt>
<dd><p>Dilates every plane of a data object by using a specific structuring element.</p>
<p>This filter applies the dialation method cvDilate of OpenCV to every plane in the source data object. The result is contained in the destination object. It can handle data objects of type uint8, uint16, int16, float32 and float64 only.</p>
<p>It is allowed to let the filter work inplace if you give the same input than destination data object, else the output data object is verified if it fits to the size and type of the source data object and if not a new one is allocated.</p>
<p>The dilation is executed using a structuring element which is (if not otherwise stated) a 3x3 kernel filled with ones. Else you can give an two-dimensional uint8 data object. Then, the function dilates the source image using the specified structuring element that determines the shape of a pixel neighborhood over which the maximum is taken:</p>
<p>dst(x,y) = max_{(x’,y’):element(x’,y’)!=0} src(x+x’,y+y’)</p>
<p>Dilation can be applied several times (parameter ‘iterations’).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sourceObj</strong> (<em>itom.dataObject</em>) – input data object of type uint8, uint16, int16, float32, float64</p></li>
<li><p><strong>destinationObj</strong> (<em>itom.dataObject</em>) – output image with the same type and size than input (inplace allowed)</p></li>
<li><p><strong>element</strong> (<em>itom.dataObject</em><em>, </em><em>optional</em>) – structuring element used for the morpholocial operation (default: None, a 3x3 rectangular structuring element is used). Else: An uint8 data object where values &gt; 0 are considered for the operation.</p></li>
<li><p><strong>anchor</strong> (<em>Sequence</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>) – position of the anchor within the element. If not given or if (-1,-1), the anchor is at the element center [default].</p></li>
<li><p><strong>iterations</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>number of times the morpholocial operation is applied [default: 1]</p>
<div class="line-block">
<div class="line"><em>Value range: [1, 65000], Default: 1</em></div>
</div>
</p></li>
<li><p><strong>borderType</strong> (<em>str</em><em>, </em><em>optional</em>) – This string defines how the filter should handle pixels at the border of the matrix. Allowed is CONSTANT [default], REPLICATE, REFLECT, WRAP, REFLECT_101. In case of a constant border, only pixels inside of the element mask are considered (morphologyDefaultBorderValue)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvDrawChessboardCorners">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvDrawChessboardCorners</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patternSize</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">corners</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patternWasFound</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvDrawChessboardCorners" title="Permalink to this definition">#</a></dt>
<dd><p>Renders the detected chessboard corners.</p>
<p>The function draws individual chessboard corners detected either as red circles if the board was not found, or as colored corners connected with lines if the board was found.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>itom.dataObject</em>) – rgba32 input and destination image (must be of type ito::rgba32).</p></li>
<li><p><strong>patternSize</strong> (<em>Sequence</em><em>[</em><em>int</em><em>]</em>) – Number of inner corners per chessboard row and column (points_per_row, points_per_column)</p></li>
<li><p><strong>corners</strong> (<em>itom.dataObject</em>) – array of detected corners (n x 2), the output of cvFindChessboardCorners or cvCornerSubPix</p></li>
<li><p><strong>patternWasFound</strong> (<em>int</em>) – <p>Parameter indicating whether the complete board was found or not.</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 1], Default: 1</em></div>
</div>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvDrawKeypoints">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvDrawKeypoints</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">keypoints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outImage</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">color</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flags</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvDrawKeypoints" title="Permalink to this definition">#</a></dt>
<dd><p>Draws keypoints.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>itom.dataObject</em>) – Source image (uint8 or rgba32).</p></li>
<li><p><strong>keypoints</strong> (<em>itom.dataObject</em>) – keypoints of the source image (n x 7) float32 data object</p></li>
<li><p><strong>outImage</strong> (<em>itom.dataObject</em>) – Output image. Its content depends on the flags value defining what is drawn in the output image. See possible flags bit values below.</p></li>
<li><p><strong>color</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>color of keypoints (pass a rgba32 value). If 0 or omitted, random colors will be used.</p>
<div class="line-block">
<div class="line"><em>All values allowed, Default: 0</em></div>
</div>
</p></li>
<li><p><strong>flags</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>flags for drawing features (bit-combination):
- 0: DEFAULT (Output image matrix will be created (Mat::create), i.e. existing memory of output image may be reused.      Two source images, matches, and single keypoints will be drawn. For each keypoint, only the center point will be      drawn (without a circle around the keypoint with the keypoint size and orientation).
- 1: DRAW_OVER_OUTIMG: Output image matrix will not be created (using Mat::create). Matches will be drawn      on existing content of output image.
- 4: DRAW_RICH_KEYPOINTS: For each keypoint, the circle around keypoint with keypoint size and orientation will be drawn.</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 5], Default: 0</em></div>
</div>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvDrawMatcher">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvDrawMatcher</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">first_image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">second_image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">first_keypoints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">second_keypoints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">matches</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_img</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">match_color</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">single_point_color</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">flags</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_match_distance</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvDrawMatcher" title="Permalink to this definition">#</a></dt>
<dd><p>Draw the obtained matches points between two images.
This function draws matches of keypoints from two images in the output image. Match is a line connecting two keypoints (circles).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>first_image</strong> (<em>itom.dataObject</em>) – Input parameter - first image to draw the matching points</p></li>
<li><p><strong>second_image</strong> (<em>itom.dataObject</em>) – Input parameter - second image to draw the matchibg points</p></li>
<li><p><strong>first_keypoints</strong> (<em>itom.dataObject</em>) – keypoints of the first image (n x 7) float32 data object</p></li>
<li><p><strong>second_keypoints</strong> (<em>itom.dataObject</em>) – keypoints of the second image (n x 7) float32 data object</p></li>
<li><p><strong>matches</strong> (<em>itom.dataObject</em>) – Input parameter -  Matches from the first image to the second one, which means that keypoints1[i] has a corresponding point in keypoints2[matches[i]]</p></li>
<li><p><strong>out_img</strong> (<em>itom.dataObject</em>) – Output parameter - Output image</p></li>
<li><p><strong>match_color</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>color of matches (pass a rgba32 value). If 0 or omitted, random colors will be used.</p>
<div class="line-block">
<div class="line"><em>All values allowed, Default: 0</em></div>
</div>
</p></li>
<li><p><strong>single_point_color</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>color of single keypoints (pass a rgba32 value). If 0 or omitted, random colors will be used.</p>
<div class="line-block">
<div class="line"><em>All values allowed, Default: 0</em></div>
</div>
</p></li>
<li><p><strong>flags</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>flags for drawing features (bit-combination):
- 0: DEFAULT: Output image matrix will be created (Mat::create), i.e. existing memory of output image may be reused.      Two source images, matches, and single keypoints will be drawn. For each keypoint, only the center point will be      drawn (without a circle around the keypoint with the keypoint size and orientation).
- 1: DRAW_OVER_OUTIMG: Output image matrix will not be created (using Mat::create). Matches will be drawn      on existing content of output image.
- 2: NOT_DRAW_SINGLE_POINTS: Single keypoints will not be drawn.
- 4: DRAW_RICH_KEYPOINTS: For each keypoint, the circle around keypoint with keypoint size and orientation will be drawn.</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 7], Default: 0</em></div>
</div>
</p></li>
<li><p><strong>max_match_distance</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>max match distance that should be drawn. If 0, every match is drawn [default]</p>
<div class="line-block">
<div class="line"><em>Value range: [0, inf], Default: 0</em></div>
</div>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvErode">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvErode</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sourceObj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destinationObj</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">element</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anchor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iterations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">borderType</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvErode" title="Permalink to this definition">#</a></dt>
<dd><p>Erodes every plane of a data object by using a specific structuring element.</p>
<p>This filter applies the erosion method cvErode of OpenCV to every plane in the source data object. The result is contained in the destination object. It can handle data objects of type uint8, uint16, int16, float32 and float64 only.</p>
<p>It is allowed to let the filter work inplace if you give the same input than destination data object, else the output data object is verified if it fits to the size and type of the source data object and if not a new one is allocated.</p>
<p>The erosion is executed using a structuring element which is (if not otherwise stated) a 3x3 kernel filled with ones. Else you can give an two-dimensional uint8 data object. Then, the function dilates the source image using the specified structuring element that determines the shape of a pixel neighborhood over which the maximum is taken:</p>
<p>dst(x,y) = min_{(x’,y’):element(x’,y’)!=0} src(x+x’,y+y’)</p>
<p>Erosion can be applied several times (parameter ‘iterations’).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sourceObj</strong> (<em>itom.dataObject</em>) – input data object of type uint8, uint16, int16, float32, float64</p></li>
<li><p><strong>destinationObj</strong> (<em>itom.dataObject</em>) – output image with the same type and size than input (inplace allowed)</p></li>
<li><p><strong>element</strong> (<em>itom.dataObject</em><em>, </em><em>optional</em>) – structuring element used for the morpholocial operation (default: None, a 3x3 rectangular structuring element is used). Else: An uint8 data object where values &gt; 0 are considered for the operation.</p></li>
<li><p><strong>anchor</strong> (<em>Sequence</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>) – position of the anchor within the element. If not given or if (-1,-1), the anchor is at the element center [default].</p></li>
<li><p><strong>iterations</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>number of times the morpholocial operation is applied [default: 1]</p>
<div class="line-block">
<div class="line"><em>Value range: [1, 65000], Default: 1</em></div>
</div>
</p></li>
<li><p><strong>borderType</strong> (<em>str</em><em>, </em><em>optional</em>) – This string defines how the filter should handle pixels at the border of the matrix. Allowed is CONSTANT [default], REPLICATE, REFLECT, WRAP, REFLECT_101. In case of a constant border, only pixels inside of the element mask are considered (morphologyDefaultBorderValue)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvEstimateAffine3DParams">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvEstimateAffine3DParams</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sources</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destinations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">inliers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ransacThreshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confidence</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvEstimateAffine3DParams" title="Permalink to this definition">#</a></dt>
<dd><p>Computes an optimal affine transformation between two 3D point sets</p>
<p>The function estimates an optimal 3D affine transformation between two 3D point sets using the RANSAC algorithm. The transformation describes then
[destination;1] = output * [source;1] for each point in sources and destinations 3D point set.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sources</strong> (<em>itom.dataObject</em>) – [n x 3] array of source points (will be converted to float64).</p></li>
<li><p><strong>destinations</strong> (<em>itom.dataObject</em>) – [n x 3] array of destination points (must have the same size than sources, will be converted to float64).</p></li>
<li><p><strong>output</strong> (<em>itom.dataObject</em>) – Output 3D affine transformation matrix 3x4 (float64)</p></li>
<li><p><strong>inliers</strong> (<em>itom.dataObject</em><em>, </em><em>optional</em>) – Output vector indicating which points are inliers (uint8)</p></li>
<li><p><strong>ransacThreshold</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>Maximum reprojection error in the RANSAC algorithm to consider a point as an inlier (default: 3.0)</p>
<div class="line-block">
<div class="line"><em>Value range: [0, inf], Default: 3</em></div>
</div>
</p></li>
<li><p><strong>confidence</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>Confidence level, between 0 and 1, for the estimated transformation. Anything between 0.95 and 0.99 is usually good enough. Values too close to 1 can slow down the estimation significantly. Values lower than 0.8-0.9 can result in an incorrectly estimated transformation.</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 1], Default: 0.99</em></div>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>ret - return value</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvFFT1D">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvFFT1D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sourceImage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvFFT1D" title="Permalink to this definition">#</a></dt>
<dd><p>1D-dimentional fourier-transformation using cv::DFT.</p>
<p>This filter tries to perform an inplace FFT for a given line or 2D-dataObject. The FFT is calculated linewise.The result is a complex-dataObject. The axis-scales and units are invertes and modified.</p>
<p>This filter internally calls the ito::dObjHelper::calcCVDFT(dObjImages, false, false, true)-function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>sourceImage</strong> (<em>itom.dataObject</em>) – Input Object handle, must be a single plane</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvFFT2D">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvFFT2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sourceImage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvFFT2D" title="Permalink to this definition">#</a></dt>
<dd><p>2D-dimentional fourier-transformation using cv::DFT.</p>
<p>This filter tries to perform an inplace FFT for a given 2D-dataObject. The FFT is calculated planewise.The result is a complex-dataObject. The axis-scales and units are invertes and modified.</p>
<p>This filter internally calls the ito::dObjHelper::calcCVDFT(dObjImages, false, false, false)-function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>sourceImage</strong> (<em>itom.dataObject</em>) – Input Object handle, must be a single plane</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvFindChessboardCorners">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvFindChessboardCorners</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataObject</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patternSize</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">corners</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">flags</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvFindChessboardCorners" title="Permalink to this definition">#</a></dt>
<dd><p>Finds the positions of internal corners of the chessboard.</p>
<p>This filter is a wrapper for the cv::method cv::findChessboardCorners.
The openCV-function attempts to determine whether the input image is a view of the chessboard pattern and locate the internal chessboard corners. The function returns a non-zero value if all of the corners are found and they are placed in a certain order (row by row, left to right in every row). Otherwise, if the function fails to find all the corners or reorder them, it returns 0. For example, a regular chessboard has 8 x 8 squares and 7 x 7 internal corners, that is, points where the black squares touch each other. The detected coordinates are approximate, and to determine their positions more accurately, the function calls cornerSubPix().</p>
<p>Remark 1: This function gives only a rough estimation of the positions. For a higher resolutions, you should usethe function cornerSubPix() with different parameters if returned coordinates are not accurate enough.This function is wrapped to itom by the filter ‘cvCornerSubPix’.</p>
<p>Remark 2: The outer frame of the dataObject / the image should not be white but have approximately the same gray value than the bright field.</p>
<p>Remark 3: The bright fields should be free of darker dirt or dust and you should apply a corse shading correction to improve the results.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataObject</strong> (<em>itom.dataObject</em>) – 8bit grayscale input image</p></li>
<li><p><strong>patternSize</strong> (<em>Sequence</em><em>[</em><em>int</em><em>]</em>) – Number of inner corners per chessboard row and column (points_per_row, points_per_column)</p></li>
<li><p><strong>corners</strong> (<em>itom.dataObject</em>) – output: float32-dataObject, [n x 2] with the coordinates of n detected corner points</p></li>
<li><p><strong>flags</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>OR Combination of various flags:</p>
<ul>
<li><p>CV_CALIB_CB_ADAPTIVE_THRESH (1) - Use adaptive thresholding to convert the image to black and white, rather than a fixed threshold level (computed from the average image brightness) [default],</p></li>
<li><p>CV_CALIB_CB_NORMALIZE_IMAGE (2) - Normalize the image gamma with equalizeHist() before applying fixed or adaptive thresholding [default],</p></li>
<li><p>CV_CALIB_CB_FILTER_QUADS (4) - Use additional criteria (like contour area, perimeter, square-like shape) to filter out false quads extracted at the contour retrieval stage,</p></li>
<li><p>CALIB_CB_FAST_CHECK (8) - Run a fast check on the image that looks for chessboard corners, and shortcut the call if none is found. This can drastically speed up the call in the degenerate condition when no chessboard is observed (recommended to pre-check image).</p></li>
</ul>
<div class="line-block">
<div class="line"><em>Value range: [0, 15], Default: 3</em></div>
</div>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>result - 0: detection failed, 1: detection has been successful</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvFindCircles">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvFindCircles</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">image</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">circles</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">dp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_dist</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">canny_threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">acc_threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_radius</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_radius</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvFindCircles" title="Permalink to this definition">#</a></dt>
<dd><p>Finds circles in a grayscale image using the Hough transform.</p>
<p>This filter is a wrapper for the OpenCV-function cv::HoughCircles.The function finds circles in a grayscale image using a modification of the Hough transform.Based on this filter, circles are identified and located.The result is a dataObject where the number of rows corresponds to the number of found circles, each row is (x,y,r).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>image</strong> (<em>itom.dataObject</em>) – input image of type uint8</p></li>
<li><p><strong>circles</strong> (<em>itom.dataObject</em>) – </p></li>
<li><p><strong>dp</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>dp: Inverse ratio of the accumulator resolution to the image resolution.</p>
<div class="line-block">
<div class="line"><em>Value range: [1, 100], Default: 1</em></div>
</div>
</p></li>
<li><p><strong>min_dist</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>Minimum center distance of the circles.</p>
<div class="line-block">
<div class="line"><em>Value range: [1, 100000], Default: 20</em></div>
</div>
</p></li>
<li><p><strong>canny_threshold</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>The higher threshold of the two passed to the Canny() edge detector (the lower one is twice smaller).</p>
<div class="line-block">
<div class="line"><em>Value range: [1, 255], Default: 200</em></div>
</div>
</p></li>
<li><p><strong>acc_threshold</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>The accumulator threshold for the circle centers at the detection stage. The smaller it is, the more false circles may be detected. Circles, corresponding to the larger accumulator values, will be returned first.</p>
<div class="line-block">
<div class="line"><em>Value range: [1, 255], Default: 100</em></div>
</div>
</p></li>
<li><p><strong>min_radius</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>Min Radius in x/y</p>
<div class="line-block">
<div class="line"><em>Value range: [0, inf], Default: 0</em></div>
</div>
</p></li>
<li><p><strong>max_radius</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>Max Radius in x/y (if 0: the maximum of the image width or height is taken)</p>
<div class="line-block">
<div class="line"><em>Value range: [0, inf], Default: 0</em></div>
</div>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvFindFundamentalMat">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvFindFundamentalMat</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">points1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">points2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">F</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">method</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">param2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">status</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvFindFundamentalMat" title="Permalink to this definition">#</a></dt>
<dd><p>Calculates a fundamental matrix from the corresponding points in two images.</p>
<p>The epipolar geometry is described by the following equation:</p>
<div class="math">
<p><span class="math">[p_2; 1]^T F [p_1; 1] = 0</span></p>
</div><p>where F is a fundamental matrix, p_1 and p_2 are corresponding points in the first and the second images, respectively.</p>
<p>The function calculates the fundamental matrix using one of four methods listed above and returns the found fundamental matrix.
Normally just one matrix is found. But in case of the 7-point algorithm, the function may return up to 3 solutions (9       imes 3 matrix that stores all 3 matrices sequentially).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>points1</strong> (<em>itom.dataObject</em>) – coordinates of the points in the first image, a matrix of type [Nx2], float32 or float64</p></li>
<li><p><strong>points2</strong> (<em>itom.dataObject</em>) – coordinates of the points in the second image, a matrix of type [Nx2], float32 or float64</p></li>
<li><p><strong>F</strong> (<em>itom.dataObject</em>) – output, fundamental matrix [3x3], float64</p></li>
<li><p><strong>method</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>Method for computing a fundamental matrix. The following values are possible: , CV_FM_7POINT (1), CV_FM_8POINT (2) [default], CV_FM_RANSAC (8), CV_FM_LMEDS (4)</p>
<div class="line-block">
<div class="line"><em>Value range: [1, 8], Default: 2</em></div>
</div>
</p></li>
<li><p><strong>param1</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>Parameter used for RANSAC. It is the maximum distance from a point to an epipolar line in pixels, beyond which the point is considered an outlier and is not used for computing the final fundamental matrix. It can be set to something like 1-3, depending on the accuracy of the point localization, image resolution, and the image noise.</p>
<div class="line-block">
<div class="line"><em>Value range: [0, inf], Default: 3</em></div>
</div>
</p></li>
<li><p><strong>param2</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>Parameter used for the RANSAC or LMedS methods only. It specifies a desirable level of confidence (probability) that the estimated matrix is correct.</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 1], Default: 0.99</em></div>
</div>
</p></li>
<li><p><strong>status</strong> (<em>itom.dataObject</em><em>, </em><em>optional</em>) – Output array of N elements, every element of which is set to 0 for outliers and to 1 for the other points. The array is computed only in the RANSAC and LMedS methods. For other methods, it is set to all 1?s. If not given, no status information is returned.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvFindHomography">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvFindHomography</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">srcPoints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dstPoints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">homography</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">interpolation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ransacReprojThreshold</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvFindHomography" title="Permalink to this definition">#</a></dt>
<dd><p>Finds a perspective transformation between two planes.</p>
<p>The functions find and return the perspective transformation H between the source and the destination planes:</p>
<div class="math">
<p><span class="math">s_i \begin{bmatrix}{x'_i}\\{y'_i}\\{1}\end{bmatrix} \sim H \begin{bmatrix}{x_i}\\{y_i}\\{1}\end{bmatrix}</span></p>
</div><p>so that the back-projection error</p>
<div class="math">
<p><span class="math">\sum _i \left(x'_i- \frac{h_{11} x_i + h_{12} y_i + h_{13}}{h_{31} x_i + h_{32} y_i + h_{33}} \right)^2 + \left(y'_i- \frac{h_{21} x_i + h_{22} y_i + h_{23}}{h_{31} x_i + h_{32} y_i + h_{33}} \right)^2</span></p>
</div><p>is minimized.</p>
<p>The function is used to find initial intrinsic and extrinsic matrices. Homography matrix is determined up to a scale. Thus, it is normalized so that h_{33}=1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>srcPoints</strong> (<em>itom.dataObject</em>) – coordinates of the points in the original plane, a matrix of type [Nx2], float32</p></li>
<li><p><strong>dstPoints</strong> (<em>itom.dataObject</em>) – coordinates of the points in the target plane, a matrix of type [Nx2], float32</p></li>
<li><p><strong>homography</strong> (<em>itom.dataObject</em>) – 3x3 homography matrix (output)</p></li>
<li><p><strong>interpolation</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>Method. The following values are possible: regular method using all points (0) [default], CV_RANSAC (8), CV_LMEDS (4)</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 4], Default: 0</em></div>
</div>
</p></li>
<li><p><strong>ransacReprojThreshold</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>maximum allowed reprojection error to treat a point pair as an inlier (used for RANSAC only)</p>
<div class="line-block">
<div class="line"><em>Value range: [0, inf], Default: 3</em></div>
</div>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvFlannBasedMatcher">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvFlannBasedMatcher</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">first_descriptors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">second_descriptors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">Matching_descriptor</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">max_distance</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">first_keypoints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">second_keypoints</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">first_best_matches_points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">second_best_matches_points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">good_matches</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvFlannBasedMatcher" title="Permalink to this definition">#</a></dt>
<dd><p>This function uses the nearest search methods to find the best matching points. Matching methods by means of Flann matcher.
This includes some nearest neighbour algorithms to calculate the distance between two points.</p>
<p>If desired, this function can also return a filtered list of matches and keypoints (keypoints1 and keypoints2) that only contain matches and keypoints whose matched distances
are bounded by max_distance. You only need to indicate parameters belonging to the best-matching process if this max_distance parameter is &gt; 0.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>first_descriptors</strong> (<em>itom.dataObject</em>) – Input parameter - (n x 128) float32 data object of descriptors from first image (queryDescriptors). These descriptors can be computed from sift/surf algorithms.</p></li>
<li><p><strong>second_descriptors</strong> (<em>itom.dataObject</em>) – Input parameter - (n x 128) float32 data object of descriptors from second image (trainDescriptors). These descriptors can be computed from sift/surf algorithms.</p></li>
<li><p><strong>Matching_descriptor</strong> (<em>itom.dataObject</em>) – Output parameter - (n x 4) float32 data object of Matching descriptor vectors using FLANN matcher. Every row contains the values (queryIdx,trainIdx,imgIdx,distance)</p></li>
<li><p><strong>max_distance</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>Maximum distance between two pair of points to calculate the best matching.</p>
<div class="line-block">
<div class="line"><em>Value range: [0, inf], Default: 0</em></div>
</div>
</p></li>
<li><p><strong>first_keypoints</strong> (<em>itom.dataObject</em><em>, </em><em>optional</em>) – Optional input parameter - corresponding key points of the first image (n x 7) float32 data object, must have the same number of rows than first_descriptors.</p></li>
<li><p><strong>second_keypoints</strong> (<em>itom.dataObject</em><em>, </em><em>optional</em>) – Optional input parameter - corresponding key points of the second image (n x 7) float32 data object, must have the same number of rows than second_descriptors.</p></li>
<li><p><strong>first_best_matches_points</strong> (<em>itom.dataObject</em><em>, </em><em>optional</em>) – Optional output parameter - (m x 2) float32 data object of best matching points from first image. each row includes (x and y coordinates), and m is the number of best matching points</p></li>
<li><p><strong>second_best_matches_points</strong> (<em>itom.dataObject</em><em>, </em><em>optional</em>) – Optional output parameter - (m x 2) float32 data object of best matching points from second image. each row includes (x and y coordinates), and m is the number of best matching points</p></li>
<li><p><strong>good_matches</strong> (<em>itom.dataObject</em><em>, </em><em>optional</em>) – Optional output parameter - (m x 4) float32 data object of good matching descriptor vectors using FLANN matcher. Every row contains the values (queryIdx,trainIdx,imgIdx,distance)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvFlipLeftRight">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvFlipLeftRight</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scrImage</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destImage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvFlipLeftRight" title="Permalink to this definition">#</a></dt>
<dd><p>This filter flips the image left to right.</p>
<p>This filter applies the flip method cvFlip of OpenCV with the flipCode &gt; 0 to a 2D source data object. The result is contained in the destination object</p>
<p>It is allowed to let the filter work inplace if you give the same input than destination data object, else the output data object is verified if it fits to the size and type of the source data object and if not a new one is allocated
.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scrImage</strong> (<em>itom.dataObject</em>) – Input image</p></li>
<li><p><strong>destImage</strong> (<em>itom.dataObject</em>) – Output image</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvFlipUpDown">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvFlipUpDown</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scrImage</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destImage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvFlipUpDown" title="Permalink to this definition">#</a></dt>
<dd><p>This filter flips the image upside down.</p>
<p>This filter applies the flip method cvFlip of OpenCV with the flipCode = 0 to a 2D source data object. The result is contained in the destination object.</p>
<p>It is allowed to let the filter work inplace if you give the same input than destination data object, else the output data object is verified if it fits to the size and type of the source data object and if not a new one is allocated
.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scrImage</strong> (<em>itom.dataObject</em>) – Input image</p></li>
<li><p><strong>destImage</strong> (<em>itom.dataObject</em>) – Output image</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvGetRotationMatrix2D">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvGetRotationMatrix2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">center</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">angle</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rotationMatrix</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvGetRotationMatrix2D" title="Permalink to this definition">#</a></dt>
<dd><p>Calculates an affine matrix of 2D rotation.
The function calculates the following matrix:</p>
<div class="line-block">
<div class="line">alpha beta  (1 - alpha) * center.x - beta * center.y        |</div>
</div>
<p><a href="#id1"><span class="problematic" id="id2">|</span></a>- beta alpha beta * center.x        + (1 - alpha) * center.y |</p>
<p>where
alpha = scale * cos(angle), beta = scale * sin(angle)
The transformation maps the rotation center to itself. This is not the target, adjust the shift.
Thr rotation can be applied by using e. g. the cvWarpAffine filter.</p>
<p>Note:
When you want to use the cvWarpAffine method with this rotation matrix your center coordinates must be in the pixel domain.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>center</strong> (<em>Sequence</em><em>[</em><em>float</em><em>]</em>) – center coordinates of the rotation of shape (x, y) in physical values of the source image.</p></li>
<li><p><strong>angle</strong> (<em>float</em>) – Rotation angle in degrees. Positive values mean counter-clockwise rotation (the coordinate origin is assumed to be the top-left corner).</p></li>
<li><p><strong>scale</strong> (<em>float</em>) – Isotropic scale factor.</p></li>
<li><p><strong>rotationMatrix</strong> (<em>itom.dataObject</em>) – rotation matrix</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvIFFT1D">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvIFFT1D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sourceImage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvIFFT1D" title="Permalink to this definition">#</a></dt>
<dd><p>1D-dimentional inverse fourier-transformation using cv::DFT.</p>
<p>This filter tries to perform an inplace FFT for a given line or 2D-dataObject. The FFT is calculated linewise.The result is a real-dataObject. The axis-scales and units are invertes and modified.</p>
<p>This filter internally calls the ito::dObjHelper::calcCVDFT(dObjImages, true, true, true)-function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>sourceImage</strong> (<em>itom.dataObject</em>) – Input Object handle, must be a single plane</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvIFFT2D">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvIFFT2D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sourceImage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvIFFT2D" title="Permalink to this definition">#</a></dt>
<dd><p>2D-dimentional inverse fourier-transformation using cv::DFT.</p>
<p>This filter tries to perform an inplace FFT for a given 2D-dataObject. The FFT is calculated planewise.The result is a real-dataObject. The axis-scales and units are invertes and modified.</p>
<p>This filter internally calls the ito::dObjHelper::calcCVDFT(dObjImages, true, true, false)-function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>sourceImage</strong> (<em>itom.dataObject</em>) – Input Object handle, must be a single plane</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvInitUndistortRectifyMap">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvInitUndistortRectifyMap</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">cameraMatrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distCoeffs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map2</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">R</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">newCameraMatrix</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvInitUndistortRectifyMap" title="Permalink to this definition">#</a></dt>
<dd><p>Computes the undistortion and rectification transformation map.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cameraMatrix</strong> (<em>itom.dataObject</em>) – Input camera matrix A = [[fx 0 cx];[0 fy cy];[0 0 1]]</p></li>
<li><p><strong>distCoeffs</strong> (<em>itom.dataObject</em>) – Input vector of distortion coefficients [1 x 4,5,8] (k1, k2, p1, p2 [, k3[, k4, k5, k6]]) of 4, 5 or 8 elements.</p></li>
<li><p><strong>size</strong> (<em>Sequence</em><em>[</em><em>int</em><em>]</em>) – undistorted image size</p></li>
<li><p><strong>map1</strong> (<em>itom.dataObject</em>) – The first output map, type is float32.</p></li>
<li><p><strong>map2</strong> (<em>itom.dataObject</em>) – The second output map, type is float32.</p></li>
<li><p><strong>R</strong> (<em>itom.dataObject</em><em>, </em><em>optional</em>) – Rectification transformation in the object space (3x3 matrix). If not given, the identity transformation is used.</p></li>
<li><p><strong>newCameraMatrix</strong> (<em>itom.dataObject</em><em>, </em><em>optional</em>) – New camera matrix A’. If not given, the camera matrix is used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvMedianBlur">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvMedianBlur</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sourceImage</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destinationImage</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">kernelSize</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvMedianBlur" title="Permalink to this definition">#</a></dt>
<dd><p>Planewise median blur filter.</p>
<p>The function smoothes an image using the median filter with the kernel-size x kernel-size aperture. Each channel of a multi-channel image is processed independently. It can handle data objects of type uint8, uint16, int16, ito::tInt32, float32 and float64 only.</p>
<p>The itom-wrapping does not work inplace currently. A new dataObject is allocated.</p>
<p>Warning: NaN-handling for floats not verified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sourceImage</strong> (<em>itom.dataObject</em>) – Image of type Integer or float32</p></li>
<li><p><strong>destinationImage</strong> (<em>itom.dataObject</em>) – Empty dataObject-hanlde. Destination is of source type</p></li>
<li><p><strong>kernelSize</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>Kernelsize in x/y</p>
<div class="line-block">
<div class="line"><em>Value range: [3, 255], Default: 3</em></div>
</div>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvMergeChannels">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvMergeChannels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputObject</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputObject</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvMergeChannels" title="Permalink to this definition">#</a></dt>
<dd><p>Reduces a [4x…xMxN] or [3x…xMxN] uint8 data object to a […xMxN] rgba32 data object where the
first dimension is merged into the color type. If the first dimension is equal to 4, the planes are used for the blue, green, red and alpha
component, in case of three, the alpha component is set to the optional alpha value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputObject</strong> (<em>itom.dataObject</em>) – uint8 data object with any shape and at least three dimensions</p></li>
<li><p><strong>outputObject</strong> (<em>itom.dataObject</em>) – rgba32 data object</p></li>
<li><p><strong>alpha</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>if the first dimension of the inputObject is 3, this alpha value is used for all alpha components in the output object</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 255], Default: 255</em></div>
</div>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvMorphologyEx">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvMorphologyEx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sourceObj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destinationObj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">operation</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">element</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">anchor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">iterations</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">borderType</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvMorphologyEx" title="Permalink to this definition">#</a></dt>
<dd><p>Erodes every plane of a data object by using a specific structuring element.</p>
<p>Performs advanced morphological transformations.The function cv::morphologyEx can perform advanced morphological transformations using an erosion and dilation as basic operations.MORPH_ERODE Any of the operations can be done in - place.In case of multi - channel images, each channel is processed independently.).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sourceObj</strong> (<em>itom.dataObject</em>) – input data object of type uint8, uint16, int16, float32, float64</p></li>
<li><p><strong>destinationObj</strong> (<em>itom.dataObject</em>) – output image with the same type and size than input (inplace allowed)</p></li>
<li><p><strong>operation</strong> (<em>int</em>) – <p>This parameters defines the operation type, 0: Erode, 1: Dilate, 2: Open, 3: Close, 4: Gradient, 5: Tophat, 6: Blackhat, 7: Hit or miss</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 7], Default: 0</em></div>
</div>
</p></li>
<li><p><strong>element</strong> (<em>itom.dataObject</em><em>, </em><em>optional</em>) – structuring element used for the morpholocial operation (default: None, a 3x3 rectangular structuring element is used). Else: An uint8 data object where values &gt; 0 are considered for the operation.</p></li>
<li><p><strong>anchor</strong> (<em>Sequence</em><em>[</em><em>int</em><em>]</em><em>, </em><em>optional</em>) – position of the anchor within the element. If not given or if (-1,-1), the anchor is at the element center [default].</p></li>
<li><p><strong>iterations</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>number of times the morpholocial operation is applied [default: 1]</p>
<div class="line-block">
<div class="line"><em>Value range: [1, 65000], Default: 1</em></div>
</div>
</p></li>
<li><p><strong>borderType</strong> (<em>str</em><em>, </em><em>optional</em>) – This string defines how the filter should hande pixels at the border of the matrix. Allowed is CONSTANT [default], REPLICATE, REFLECT, WRAP, REFLECT_101. In case of a constant border, only pixels inside of the element mask are considered (morphologyDefaultBorderValue)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvProjectPoints">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvProjectPoints</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputObject</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputObject</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distCoeff</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">RVec</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">TVec</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvProjectPoints" title="Permalink to this definition">#</a></dt>
<dd><p>Project points from object into image space using the given calibration matrices,
distortion coefficients rotation and tralsation vector.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputObject</strong> (<em>itom.dataObject</em>) – input image</p></li>
<li><p><strong>outputObject</strong> (<em>itom.dataObject</em>) – output image that has the size dsize and the same type as input image</p></li>
<li><p><strong>M</strong> (<em>itom.dataObject</em>) – 3x3 camera fundamental matrix</p></li>
<li><p><strong>distCoeff</strong> (<em>itom.dataObject</em>) – matrix with distortion coefficients</p></li>
<li><p><strong>RVec</strong> (<em>itom.dataObject</em>) – rotation vector</p></li>
<li><p><strong>TVec</strong> (<em>itom.dataObject</em>) – translation vector</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvRemap">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvRemap</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destination</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">map2</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">interpolation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">borderMode</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">borderValue</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvRemap" title="Permalink to this definition">#</a></dt>
<dd><p>Applies a generic geometrical transformation to an image.</p>
<p>The function remap transforms the source image using the specified map:</p>
<div class="math">
<p><span class="math">dst(x,y) = src(map1(x, y), map2(x, y))</span></p>
</div><p>where values of pixels with non-integer coordinates are computed using one of available interpolation methods. map_x and map_y can be encoded as
separate floating-point maps in map_1 and map_2 respectively, or interleaved floating-point maps of (x,y) in map_1 ,
or fixed-point maps created by using convertMaps() . The reason you might want to convert from floating to fixed-point representations of a map is
that they can yield much faster (~2x) remapping operations. In the converted case, map_1 contains pairs (cvFloor(x), cvFloor(y)) and map_2 contains
indices in a table of interpolation coefficients.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source</strong> (<em>itom.dataObject</em>) – source image</p></li>
<li><p><strong>destination</strong> (<em>itom.dataObject</em>) – destination image. It hast the same size as map1 and the same type as src.</p></li>
<li><p><strong>map1</strong> (<em>itom.dataObject</em>) – The first map of x values</p></li>
<li><p><strong>map2</strong> (<em>itom.dataObject</em>) – The second map of y values</p></li>
<li><p><strong>interpolation</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>Interpolation method. The following values are possible:
INTER_NEAREST (0)
INTER_LINEAR (1)
INTER_CUBIC (2)
INTER_LANCZOS4 (4)</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 4], Default: 1</em></div>
</div>
</p></li>
<li><p><strong>borderMode</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>Pixel extrapolation method. When boderMode == BORDER_TRANSPARENT (5), it means that the pixels in the destination image that corresponds to the outliers in the source image are not modified by the function.
The following values are possible:
BORDER_CONSTANT (0)
BORDER_REPLICATE (1)
BORDER_REFLECT (2)
BORDER_WRAP (3)
BORDER_REFLECT101 (4)
BORDER_TRANSPARENT (5)
BORDER_DEFAULT (4)
BORDER_ISOLATED (16)</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 16], Default: 0</em></div>
</div>
</p></li>
<li><p><strong>borderValue</strong> (<em>float</em><em>, </em><em>optional</em>) – value used in case of a constant border. By default, it is 0</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvRemoveSpikes">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvRemoveSpikes</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sourceObject</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destinationObject</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">kernelSize</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lowestValue</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">highestValue</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">newValue</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvRemoveSpikes" title="Permalink to this definition">#</a></dt>
<dd><p>Set single spikes at measurement edges to a new value.</p>
<p>This filter creates a binary mask for the input object. The value of mask(y,x) will be 1 if value of input(y,x) is within the specified range and is finite.The mask is eroded and than dilated by kernel size using openCV cv::erode and cv::dilate with a single iteration. In the last step the value of output(y,x) is set to newValue if mask(y,x) is 0.</p>
<p>It is allowed to let the filter work inplace if you give the same source and destination data object, else the destination data object is verified if it fits to the size and type of the source data object and if not a new one is allocated and the input data is copied to the new object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sourceObject</strong> (<em>itom.dataObject</em>) – 32 or 64 bit floating point input image</p></li>
<li><p><strong>destinationObject</strong> (<em>itom.dataObject</em>) – 32 or 64 bit floating point output image</p></li>
<li><p><strong>kernelSize</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>N defines the N x N kernel</p>
<div class="line-block">
<div class="line"><em>Value range: [3, 13], Default: 5</em></div>
</div>
</p></li>
<li><p><strong>lowestValue</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>Lowest value to consider as valid</p>
<div class="line-block">
<div class="line"><em>All values allowed, Default: 0</em></div>
</div>
</p></li>
<li><p><strong>highestValue</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>Highest value to consider as valid</p>
<div class="line-block">
<div class="line"><em>All values allowed, Default: 1</em></div>
</div>
</p></li>
<li><p><strong>newValue</strong> (<em>float</em><em>, </em><em>optional</em>) – <p>Replacement value for spike elements</p>
<div class="line-block">
<div class="line"><em>All values allowed, Default: nan</em></div>
</div>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvResize">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvResize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputObject</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputObject</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fy</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">interpolation</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvResize" title="Permalink to this definition">#</a></dt>
<dd><p>Resizes an image</p>
<p>The function resize resizes the image ‘inputObject’ down to or up by the specific factors.</p>
<p>To shrink an image, it will generally look best with CV_INTER_AREA interpolation, whereas to enlarge an image,
it will generally look best with CV_INTER_CUBIC (slow) or CV_INTER_LINEAR (faster but still looks OK).
The axisScale properties of the x- and y-axes of the outputObject are divided by fx and fy respectively, while the offset values are multiplied with fx and fy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputObject</strong> (<em>itom.dataObject</em>) – input image (2D after an optional squeeze operation)</p></li>
<li><p><strong>outputObject</strong> (<em>itom.dataObject</em>) – output image, will have the same type than inputObject. Its size corresponds to the size of the input object multiplied with fx and fy respectively.</p></li>
<li><p><strong>fx</strong> (<em>float</em>) – <p>scale factor along the horizontal axis.</p>
<div class="line-block">
<div class="line"><em>Value range: [1e-06, inf], Default: 1</em></div>
</div>
</p></li>
<li><p><strong>fy</strong> (<em>float</em>) – <p>scale factor along the vertical axis.</p>
<div class="line-block">
<div class="line"><em>Value range: [1e-06, inf], Default: 1</em></div>
</div>
</p></li>
<li><p><strong>interpolation</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>Interpolation method. The following values are possible:</p>
<p>INTER_NEAREST (0)
INTER_LINEAR (1)
INTER_AREA (3)
INTER_CUBIC (2)
INTER_LANCZOS4 (4)</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 4], Default: 1</em></div>
</div>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvRotate180">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvRotate180</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scrImage</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destImage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvRotate180" title="Permalink to this definition">#</a></dt>
<dd><p>This filter rotates the image by 180?.</p>
<p>This filter applies the flip method cvFlip from OpenCV horizontally and vertically to rotate the object. The result is contained in the destination object</p>
<p>It is allowed to let the filter work inplace if you give the same input than destination data object, else the output data object is verified if it fits to the size and type of the source data object and if not a new one is allocated.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scrImage</strong> (<em>itom.dataObject</em>) – Input image</p></li>
<li><p><strong>destImage</strong> (<em>itom.dataObject</em>) – Output image</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvRotateM90">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvRotateM90</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scrImage</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destImage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvRotateM90" title="Permalink to this definition">#</a></dt>
<dd><p>This filter rotates the image by 90? clock wise.</p>
<p>This filter applies the flip method cvFlip and the transpose method cvTranspose of OpenCV to rotate the object. The result is contained in the destination object</p>
<p>It is allowed to let the filter work pseudo inplace if you give the same input than destination data object, else the output data object is verified if it fits to the size and type of the source data object and if not a new one is allocated.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scrImage</strong> (<em>itom.dataObject</em>) – Input image</p></li>
<li><p><strong>destImage</strong> (<em>itom.dataObject</em>) – Output image</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvRotateP90">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvRotateP90</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scrImage</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destImage</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvRotateP90" title="Permalink to this definition">#</a></dt>
<dd><p>This filter rotates the image by 90? count clock wise.</p>
<p>This filter applies the flip method cvFlip and the transpose method cvTranspose of OpenCV to rotate the object. The result is contained in the destination object</p>
<p>It is allowed to let the filter work pseudo inplace if you give the same input than destination data object, else the output data object is verified if it fits to the size and type of the source data object and if not a new one is allocated.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>scrImage</strong> (<em>itom.dataObject</em>) – Input image</p></li>
<li><p><strong>destImage</strong> (<em>itom.dataObject</em>) – Output image</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvSplitChannels">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvSplitChannels</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">rgbaObject</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputObject</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvSplitChannels" title="Permalink to this definition">#</a></dt>
<dd><p>Converts a rgba32 data object (with four channels blue, green, red, alpha) into
an output data object of type ‘uint8’ and a shape that has one dimension more than the input object and the first dimension is equal to 4.
The four color components are then distributed into the 4 planes of the first dimension.</p>
<p>For instance a 4x5x3, rgba32 data objects leads to a 4x4x5x3 uint8 data object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>rgbaObject</strong> (<em>itom.dataObject</em>) – rgba32 data object with any shape</p></li>
<li><p><strong>outputObject</strong> (<em>itom.dataObject</em>) – uint8 data object with new shape [4,shape] where shape is the original shape. The inserted 4 dimensions represent the color components (b,g,r,alpha) of the source object.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvThreshold">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvThreshold</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destination</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">threshold</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">maxValue</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">type</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvThreshold" title="Permalink to this definition">#</a></dt>
<dd><p>Applies a fixed-level threshold to each array element..</p>
<p>The function applies fixed-level thresholding to a multiple-channel array.
The function is typically used to get a bi-level (binary) image out of a grayscale image (compare could be also used for this purpose)
or for removing a noise, that is, filtering out pixels with too small or too large values.
There are several types of thresholding supported by the function. They are determined by type parameter.</p>
<p>Also, the special values THRESH_OTSU or THRESH_TRIANGLE may be combined with one of the above values.
In these cases, the function determines the optimal threshold value using the Otsu’s or Triangle algorithm and uses it instead of the specified thresh.</p>
<p>Note:
Currently, the Otsu’s and Triangle methods are implemented only for 8-bit single-channel images.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source</strong> (<em>itom.dataObject</em>) – source image</p></li>
<li><p><strong>destination</strong> (<em>itom.dataObject</em>) – destination image. It hast the same size as map1 and the same type as src.</p></li>
<li><p><strong>threshold</strong> (<em>float</em>) – <p>threshold value.</p>
<div class="line-block">
<div class="line"><em>Value range: [2.22507e-308, inf], Default: 0</em></div>
</div>
</p></li>
<li><p><strong>maxValue</strong> (<em>float</em>) – <p>maximum value to use with the THRESH_BINARY and THRESH_BINARY_INV thresholding types.</p>
<div class="line-block">
<div class="line"><em>Value range: [2.22507e-308, inf], Default: 0</em></div>
</div>
</p></li>
<li><p><strong>type</strong> (<em>int</em>) – <p>threshold type
THRESH_BINARY (0)
THRESH_BINARY_INV (1)
THRESH_TRUNC (2)
THRESH_TOZERO (3)
THRESH_TOZERO_INV (4)
THRESH_MASK (7)
THRESH_OTSU (8)
THRESH_TRIANGLE (16)</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 16], Default: 0</em></div>
</div>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvUndistort">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvUndistort</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destination</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cameraMatrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distCoeffs</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">newCameraMatrix</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvUndistort" title="Permalink to this definition">#</a></dt>
<dd><p>Transforms an image to compensate for lens distortion.</p>
<p>The function transforms an image to compensate radial and tangential lens distortion.
The function is simply a combination of cvInitUndistortRectifyMap() (with unity R) and cvRemap() (with bilinear interpolation).
See the former function for details of the transformation being performed.</p>
<p>Those pixels in the destination image, for which there is no correspondent pixels in the source image, are filled with zeros (black color).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source</strong> (<em>itom.dataObject</em>) – Input (distorted) image (all datatypes)</p></li>
<li><p><strong>destination</strong> (<em>itom.dataObject</em>) – Output (corrected) image that has the same size and type as source</p></li>
<li><p><strong>cameraMatrix</strong> (<em>itom.dataObject</em>) – Input camera matrix A = [[fx 0 cx];[0 fy cy];[0 0 1]]</p></li>
<li><p><strong>distCoeffs</strong> (<em>itom.dataObject</em>) – Input vector of distortion coefficients [1 x 4,5,8] (k1, k2, p1, p2 [, k3[, k4, k5, k6]]) of 4, 5 or 8 elements.</p></li>
<li><p><strong>newCameraMatrix</strong> (<em>itom.dataObject</em><em>, </em><em>optional</em>) – Camera matrix of the distorted image. By default (if not given), it is the same as cameraMatrix but you may additionally scale and shift the result by using a different matrix.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvUndistortPoints">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvUndistortPoints</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destination</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cameraMatrix</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">distCoeffs</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">R</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">P</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvUndistortPoints" title="Permalink to this definition">#</a></dt>
<dd><p>Computes the ideal point coordinates from the observed point coordinates.</p>
<p>The function is similar to cvUndistort() and cvInitUndistortRectifyMap() but it operates on a sparse set of points instead of a raster image. Also the function performs a reverse transformation to cvProjectPoints() .
In case of a 3D object, it does not reconstruct its 3D coordinates, but for a planar object, it does, up to a translation vector, if the proper R is specified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>source</strong> (<em>itom.dataObject</em>) – Observed point coordinates (Nx2) float32</p></li>
<li><p><strong>destination</strong> (<em>itom.dataObject</em>) – Output (corrected) image that has the same size and type as source</p></li>
<li><p><strong>cameraMatrix</strong> (<em>itom.dataObject</em>) – Input camera matrix A = [[fx 0 cx];[0 fy cy];[0 0 1]]</p></li>
<li><p><strong>distCoeffs</strong> (<em>itom.dataObject</em>) – Input vector of distortion coefficients [1 x 4,5,8] (k1, k2, p1, p2 [, k3[, k4, k5, k6]]) of 4, 5 or 8 elements.</p></li>
<li><p><strong>R</strong> (<em>itom.dataObject</em><em>, </em><em>optional</em>) – Rectification transformation in the object space (3x3 matrix). If not given, the identity transformation is used.</p></li>
<li><p><strong>P</strong> (<em>itom.dataObject</em><em>, </em><em>optional</em>) – New camera matrix (3x3) or new projection matrix (3x4). If not given, the identity new camera matrix is used.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvWarpAffine">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvWarpAffine</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sourceObj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destinationObj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transformationObj</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">destinationSize</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">flags</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">borderType</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">borderValue</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvWarpAffine" title="Permalink to this definition">#</a></dt>
<dd><p>Applies an affine transformation onto a 2D dataObject.
The function warpAffine transforms the source dataObject using the specified matrix:</p>
<div class="math">
<p><span class="math">dst(x,y)=src(M11x+M12y+M13,M21x+M22y+M23):</span></p>
</div><p>When the flag WARP_INVERSE_MAP is set.
Otherwise, the transformation is first inverted with invertAffineTransform
and then put in the formula above instead of M.</p>
<p>Note:
The rotation matrix of the cvGetRotationMatrix2D filter can be used.
The matrix must correspond to the pixel domain.</p>
<p>No metaInformation is set to the destinationObj because the physical units
of the target object differ from each other depending on the algorithm parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sourceObj</strong> (<em>itom.dataObject</em>) – input data object of type uint8, uint16, int16, float32, float64.</p></li>
<li><p><strong>destinationObj</strong> (<em>itom.dataObject</em>) – output image with the same type and size than input (inplace allowed).</p></li>
<li><p><strong>transformationObj</strong> (<em>itom.dataObject</em>) – transformation matrix dataObject of shape 2x3.</p></li>
<li><p><strong>destinationSize</strong> (<em>Sequence</em><em>[</em><em>int</em><em>]</em>) – List of (width, height) of the destination dataObject.</p></li>
<li><p><strong>flags</strong> (<em>str</em><em>, </em><em>optional</em>) – <p>Combination of interpolation methods (see OpenCV InterpolationFlags) and the optional flag WARP_INVERSE_MAP that means that M is the inverse transformation (dst -&gt; src).</p>
<div class="line-block">
<div class="line"><em>Match: [“NEAREST”, “LINEAR”, “CUBIC”, “AREA”, “LANCZOS4”, “WARP_INVERSE_MAP”], Default: “LINEAR”</em></div>
</div>
</p></li>
<li><p><strong>borderType</strong> (<em>str</em><em>, </em><em>optional</em>) – <p>This string defines how the filter should handle pixels at the border of the destinationObj. In case of a constant border, only pixels inside of the element mask are considered.</p>
<div class="line-block">
<div class="line"><em>Match: [“CONSTANT”, “REPLICATE”, “REFLECT”, “WRAP”, “REFLECT_101”, “TRANSPARENT”], Default: “CONSTANT”</em></div>
</div>
</p></li>
</ul>
</dd>
</dl>
<p>:param borderValue : value used in case of a constant border; by default, it is 0.0</p>
<blockquote>
<div><div class="line-block">
<div class="line"><em>Value range: [2.22507e-308, inf], Default: 0</em></div>
</div>
</div></blockquote>
<p>:type borderValue : float, optional</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="itom.algorithms.cvWarpPerspective">
<span class="sig-prename descclassname"><span class="pre">itom.algorithms.</span></span><span class="sig-name descname"><span class="pre">cvWarpPerspective</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputObject</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">outputObject</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">M</span></span></em><span class="optional">[</span>, <em class="sig-param"><span class="n"><span class="pre">interpolation</span></span></em><span class="optional">]</span><span class="sig-paren">)</span><a class="headerlink" href="#itom.algorithms.cvWarpPerspective" title="Permalink to this definition">#</a></dt>
<dd><p>Applies a perspective transformation to an image</p>
<p>The function warpPerspective transforms the source image using the specified matrix H</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputObject</strong> (<em>itom.dataObject</em>) – input image</p></li>
<li><p><strong>outputObject</strong> (<em>itom.dataObject</em>) – output image that has the size dsize and the same type as input image</p></li>
<li><p><strong>M</strong> (<em>itom.dataObject</em>) – 3x3 transformation matrix</p></li>
<li><p><strong>interpolation</strong> (<em>int</em><em>, </em><em>optional</em>) – <p>Interpolation method. The following values are possible: INTER_LINEAR (1), INTER_NEAREST (0)</p>
<div class="line-block">
<div class="line"><em>Value range: [0, 1], Default: 1</em></div>
</div>
</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
</section>


                </article>
              
              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="fringeProj.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">5.7. </span>Fringe Proj</p>
      </div>
    </a>
    <a class="right-next"
       href="pclTools.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">5.9. </span>PclTools</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">5.8.1. Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#filters">5.8.2. Filters</a><ul class="visible nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvBilateralFilter"><code class="docutils literal notranslate"><span class="pre">cvBilateralFilter()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvBlur"><code class="docutils literal notranslate"><span class="pre">cvBlur()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvCalibrateCamera"><code class="docutils literal notranslate"><span class="pre">cvCalibrateCamera()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvCannyEdge"><code class="docutils literal notranslate"><span class="pre">cvCannyEdge()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvComputeCorrespondEpilines"><code class="docutils literal notranslate"><span class="pre">cvComputeCorrespondEpilines()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvCornerSubPix"><code class="docutils literal notranslate"><span class="pre">cvCornerSubPix()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvCvtColor"><code class="docutils literal notranslate"><span class="pre">cvCvtColor()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvDilate"><code class="docutils literal notranslate"><span class="pre">cvDilate()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvDrawChessboardCorners"><code class="docutils literal notranslate"><span class="pre">cvDrawChessboardCorners()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvDrawKeypoints"><code class="docutils literal notranslate"><span class="pre">cvDrawKeypoints()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvDrawMatcher"><code class="docutils literal notranslate"><span class="pre">cvDrawMatcher()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvErode"><code class="docutils literal notranslate"><span class="pre">cvErode()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvEstimateAffine3DParams"><code class="docutils literal notranslate"><span class="pre">cvEstimateAffine3DParams()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvFFT1D"><code class="docutils literal notranslate"><span class="pre">cvFFT1D()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvFFT2D"><code class="docutils literal notranslate"><span class="pre">cvFFT2D()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvFindChessboardCorners"><code class="docutils literal notranslate"><span class="pre">cvFindChessboardCorners()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvFindCircles"><code class="docutils literal notranslate"><span class="pre">cvFindCircles()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvFindFundamentalMat"><code class="docutils literal notranslate"><span class="pre">cvFindFundamentalMat()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvFindHomography"><code class="docutils literal notranslate"><span class="pre">cvFindHomography()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvFlannBasedMatcher"><code class="docutils literal notranslate"><span class="pre">cvFlannBasedMatcher()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvFlipLeftRight"><code class="docutils literal notranslate"><span class="pre">cvFlipLeftRight()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvFlipUpDown"><code class="docutils literal notranslate"><span class="pre">cvFlipUpDown()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvGetRotationMatrix2D"><code class="docutils literal notranslate"><span class="pre">cvGetRotationMatrix2D()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvIFFT1D"><code class="docutils literal notranslate"><span class="pre">cvIFFT1D()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvIFFT2D"><code class="docutils literal notranslate"><span class="pre">cvIFFT2D()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvInitUndistortRectifyMap"><code class="docutils literal notranslate"><span class="pre">cvInitUndistortRectifyMap()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvMedianBlur"><code class="docutils literal notranslate"><span class="pre">cvMedianBlur()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvMergeChannels"><code class="docutils literal notranslate"><span class="pre">cvMergeChannels()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvMorphologyEx"><code class="docutils literal notranslate"><span class="pre">cvMorphologyEx()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvProjectPoints"><code class="docutils literal notranslate"><span class="pre">cvProjectPoints()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvRemap"><code class="docutils literal notranslate"><span class="pre">cvRemap()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvRemoveSpikes"><code class="docutils literal notranslate"><span class="pre">cvRemoveSpikes()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvResize"><code class="docutils literal notranslate"><span class="pre">cvResize()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvRotate180"><code class="docutils literal notranslate"><span class="pre">cvRotate180()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvRotateM90"><code class="docutils literal notranslate"><span class="pre">cvRotateM90()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvRotateP90"><code class="docutils literal notranslate"><span class="pre">cvRotateP90()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvSplitChannels"><code class="docutils literal notranslate"><span class="pre">cvSplitChannels()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvThreshold"><code class="docutils literal notranslate"><span class="pre">cvThreshold()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvUndistort"><code class="docutils literal notranslate"><span class="pre">cvUndistort()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvUndistortPoints"><code class="docutils literal notranslate"><span class="pre">cvUndistortPoints()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvWarpAffine"><code class="docutils literal notranslate"><span class="pre">cvWarpAffine()</span></code></a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#itom.algorithms.cvWarpPerspective"><code class="docutils literal notranslate"><span class="pre">cvWarpPerspective()</span></code></a></li>
</ul>
</li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">
  <div class="tocsection sourcelink">
    <a href="../../_sources/plugins/algorithms/openCVFilters.rst.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">
  <p class="copyright">
    
      © Copyright 2011-2023, Institut für Technische Optik (ITO), University Stuttgart. Bug report: https://github.com/itom-project/plugins/issues.
      <br/>
    
  </p>
</div>
      
        <div class="footer-item">
  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.0.1.
    <br/>
  </p>
</div>
      
    </div>
  
  
    <div class="footer-items__end">
      
        <div class="footer-item"><p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.13.3.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>